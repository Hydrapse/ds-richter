{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ydata_profiling\n",
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "import os.path as osp\n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "pd.set_option('display.max_columns', 38)\n",
    "\n",
    "DATA_DIR = \"/home/gangda/workspace/ds-richter/data\"\n",
    "split_set = \"2_3\"\n",
    "\n",
    "X = pd.read_csv(osp.join(DATA_DIR, 'train_{}_values.csv'.format(split_set)), index_col='building_id')\n",
    "y = pd.read_csv(osp.join(DATA_DIR, 'train_{}_labels.csv'.format(split_set)), index_col='building_id')\n",
    "X_test = pd.read_csv(DATA_DIR + '/test_values.csv', index_col='building_id')\n",
    "\n",
    "cat_cols=['geo_level_1_id','geo_level_2_id','geo_level_3_id',\n",
    "    #    'age','area_percentage','height_percentage', 'count_families','count_floors_pre_eq',\n",
    "    #    'land_surface_condition','foundation_type', 'roof_type',\n",
    "    #    'ground_floor_type', 'other_floor_type', 'position',\n",
    "    #    'plan_configuration', 'legal_ownership_status',\n",
    "       'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
    "       \n",
    "\t\t'land_surface_condition_n', 'land_surface_condition_o',\n",
    "\t\t'land_surface_condition_t', 'foundation_type_h', 'foundation_type_i',\n",
    "\t\t'foundation_type_r', 'foundation_type_u', 'foundation_type_w',\n",
    "\t\t'roof_type_n', 'roof_type_q', 'roof_type_x', 'ground_floor_type_f',\n",
    "\t\t'ground_floor_type_m', 'ground_floor_type_v', 'ground_floor_type_x',\n",
    "\t\t'ground_floor_type_z', 'other_floor_type_j', 'other_floor_type_q',\n",
    "\t\t'other_floor_type_s', 'other_floor_type_x', 'position_j', 'position_o',\n",
    "\t\t'position_s', 'position_t', 'plan_configuration_a',\n",
    "\t\t'plan_configuration_c', 'plan_configuration_d', 'plan_configuration_f',\n",
    "\t\t'plan_configuration_m', 'plan_configuration_n', 'plan_configuration_o',\n",
    "\t\t'plan_configuration_q', 'plan_configuration_s', 'plan_configuration_u',\n",
    "\t\t'legal_ownership_status_a', 'legal_ownership_status_r',\n",
    "\t\t'legal_ownership_status_v', 'legal_ownership_status_w']\n",
    "\n",
    "categorical_cols=['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type', 'position', 'plan_configuration', 'legal_ownership_status']\n",
    "\n",
    "X = pd.get_dummies(X, columns=categorical_cols)\n",
    "y = y - 2\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'metric': 'None',\n",
    "    'seed': 42,\n",
    "    \"bagging_fraction\": 0.8883295045279088,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"feature_fraction\": 0.5542528475943183,\n",
    "    \"lambda_l1\": 1.4756834962246912e-07,\n",
    "    \"lambda_l2\": 0.001245081454069126,\n",
    "    \"min_child_samples\": 14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning:\n",
      "\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning:\n",
      "\n",
      "'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 69694, number of negative: 118687\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10722\n",
      "[LightGBM] [Info] Number of data points in the train set: 188381, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369963 -> initscore=-0.532376\n",
      "[LightGBM] [Info] Start training from score -0.532376\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's F1: 0.725101\tvalid_1's F1: 0.700451\n",
      "[200]\ttraining's F1: 0.737287\tvalid_1's F1: 0.702488\n",
      "[300]\ttraining's F1: 0.74137\tvalid_1's F1: 0.702863\n",
      "[400]\ttraining's F1: 0.744814\tvalid_1's F1: 0.704282\n",
      "[500]\ttraining's F1: 0.747414\tvalid_1's F1: 0.704059\n",
      "[600]\ttraining's F1: 0.75088\tvalid_1's F1: 0.703632\n",
      "[700]\ttraining's F1: 0.752824\tvalid_1's F1: 0.70533\n",
      "[800]\ttraining's F1: 0.75563\tvalid_1's F1: 0.705164\n",
      "[900]\ttraining's F1: 0.757684\tvalid_1's F1: 0.705463\n",
      "[1000]\ttraining's F1: 0.760104\tvalid_1's F1: 0.70564\n",
      "Early stopping, best iteration is:\n",
      "[890]\ttraining's F1: 0.757423\tvalid_1's F1: 0.706485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning:\n",
      "\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning:\n",
      "\n",
      "'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 69757, number of negative: 118624\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10712\n",
      "[LightGBM] [Info] Number of data points in the train set: 188381, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370297 -> initscore=-0.530941\n",
      "[LightGBM] [Info] Start training from score -0.530941\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's F1: 0.728954\tvalid_1's F1: 0.693767\n",
      "[200]\ttraining's F1: 0.741108\tvalid_1's F1: 0.696447\n",
      "[300]\ttraining's F1: 0.745336\tvalid_1's F1: 0.697339\n",
      "[400]\ttraining's F1: 0.748709\tvalid_1's F1: 0.697934\n",
      "[500]\ttraining's F1: 0.751655\tvalid_1's F1: 0.697736\n",
      "[600]\ttraining's F1: 0.754824\tvalid_1's F1: 0.697722\n",
      "Early stopping, best iteration is:\n",
      "[457]\ttraining's F1: 0.750863\tvalid_1's F1: 0.698973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning:\n",
      "\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning:\n",
      "\n",
      "'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 69820, number of negative: 118562\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10699\n",
      "[LightGBM] [Info] Number of data points in the train set: 188382, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370630 -> initscore=-0.529516\n",
      "[LightGBM] [Info] Start training from score -0.529516\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's F1: 0.72743\tvalid_1's F1: 0.700217\n",
      "[200]\ttraining's F1: 0.739662\tvalid_1's F1: 0.703761\n",
      "[300]\ttraining's F1: 0.743764\tvalid_1's F1: 0.704966\n",
      "[400]\ttraining's F1: 0.746871\tvalid_1's F1: 0.705609\n",
      "[500]\ttraining's F1: 0.750268\tvalid_1's F1: 0.70617\n",
      "[600]\ttraining's F1: 0.752206\tvalid_1's F1: 0.706717\n",
      "[700]\ttraining's F1: 0.755058\tvalid_1's F1: 0.707073\n",
      "[800]\ttraining's F1: 0.75784\tvalid_1's F1: 0.706795\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's F1: 0.754798\tvalid_1's F1: 0.707778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning:\n",
      "\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning:\n",
      "\n",
      "'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 69838, number of negative: 118544\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10678\n",
      "[LightGBM] [Info] Number of data points in the train set: 188382, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370725 -> initscore=-0.529106\n",
      "[LightGBM] [Info] Start training from score -0.529106\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's F1: 0.725231\tvalid_1's F1: 0.696472\n",
      "[200]\ttraining's F1: 0.737748\tvalid_1's F1: 0.701372\n",
      "[300]\ttraining's F1: 0.742792\tvalid_1's F1: 0.701681\n",
      "[400]\ttraining's F1: 0.746192\tvalid_1's F1: 0.70152\n",
      "[500]\ttraining's F1: 0.749329\tvalid_1's F1: 0.702335\n",
      "[600]\ttraining's F1: 0.752451\tvalid_1's F1: 0.701473\n",
      "[700]\ttraining's F1: 0.754612\tvalid_1's F1: 0.701972\n",
      "[800]\ttraining's F1: 0.757297\tvalid_1's F1: 0.702138\n",
      "[900]\ttraining's F1: 0.759973\tvalid_1's F1: 0.703568\n",
      "[1000]\ttraining's F1: 0.761356\tvalid_1's F1: 0.704259\n",
      "[1100]\ttraining's F1: 0.763388\tvalid_1's F1: 0.704291\n",
      "[1200]\ttraining's F1: 0.766262\tvalid_1's F1: 0.703162\n",
      "Early stopping, best iteration is:\n",
      "[1005]\ttraining's F1: 0.761777\tvalid_1's F1: 0.704884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning:\n",
      "\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning:\n",
      "\n",
      "'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 69763, number of negative: 118619\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10709\n",
      "[LightGBM] [Info] Number of data points in the train set: 188382, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370327 -> initscore=-0.530813\n",
      "[LightGBM] [Info] Start training from score -0.530813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "e:\\USC\\Spring 23\\567\\Homework\\Final Project\\workspace\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's F1: 0.729082\tvalid_1's F1: 0.701057\n",
      "[200]\ttraining's F1: 0.740367\tvalid_1's F1: 0.702207\n",
      "[300]\ttraining's F1: 0.745017\tvalid_1's F1: 0.703107\n",
      "[400]\ttraining's F1: 0.748108\tvalid_1's F1: 0.702754\n",
      "[500]\ttraining's F1: 0.751057\tvalid_1's F1: 0.703509\n",
      "[600]\ttraining's F1: 0.753952\tvalid_1's F1: 0.703481\n",
      "[700]\ttraining's F1: 0.756021\tvalid_1's F1: 0.70368\n",
      "[800]\ttraining's F1: 0.758526\tvalid_1's F1: 0.704193\n",
      "Early stopping, best iteration is:\n",
      "[644]\ttraining's F1: 0.754685\tvalid_1's F1: 0.704767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds= np.where(preds < 0.5, 0, 1)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    return 'F1', f1, True\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "best_models = []\n",
    "val_acc = 0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    y_train = y.iloc[train_index, :]\n",
    "\n",
    "    X_val = X.iloc[val_index, :]\n",
    "    y_val = y.iloc[val_index, :]\n",
    "\n",
    "    d_training = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_cols, free_raw_data=False)\n",
    "    d_test = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_cols, free_raw_data=False)\n",
    "\n",
    "    model = lgb.train(params, train_set=d_training, valid_sets=[d_training, d_test], feval=lgb_f1,\n",
    "                      verbose_eval=100, early_stopping_rounds=200, num_boost_round=2000)\n",
    "\n",
    "    # val_preds = model.predict(X_val)\n",
    "    # print(val_preds)\n",
    "    # val_acc += f1_score(y_val, val_preds)\n",
    "    best_models.append(model)\n",
    "    # print(f'val_acc: {val_acc/len(best_models): .5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80456197, 0.07488217, 0.82034384, ..., 0.979163  , 0.00266198,\n",
       "       0.92753116])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_probs = []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_val = X.iloc[val_index, :]\n",
    "    val_probs.append(best_models[i].predict(X_val))\n",
    "\n",
    "val_probs = np.concatenate(val_probs, axis=0)\n",
    "val_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69614389, 0.08379004, 0.20708981, ..., 0.13067967, 0.14235603,\n",
       "       0.06230433])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs = None\n",
    "for best_model in best_models:\n",
    "    if test_probs is None:\n",
    "        test_probs = best_model.predict(X_test, num_iteration=best_model.best_iteration)\n",
    "    else:\n",
    "        test_probs += best_model.predict(X_test, num_iteration=best_model.best_iteration)\n",
    "\n",
    "test_probs /= len(best_models)\n",
    "test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_DIR + '/intermediate/lightgbm_{}fold_{}_train.npy'.format(kf.n_splits, split_set), val_probs)\n",
    "np.save(DATA_DIR + '/intermediate/lightgbm_{}fold_{}_test.npy'.format(kf.n_splits, split_set), test_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
